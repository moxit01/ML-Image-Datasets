# ML-Image-Datasets

An Amazing list of awesome, free machine learning Image datasets you can get with below links.

Get your Machine Learning right image dataset to train your Machine Learning models.

## Image Datasets Links

* [Visual Genome](http://visualgenome.org/)

Visual Genome is a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language which range from people, to buildings, to signs and lots more.

Contains:
108,077 Images,
5.4 Million Region Descriptions,
1.7 Million Visual Question Answers,
3.8 Million Object Instances,
2.8 Million Attributes,
2.3 Million Relationships.
Everything Mapped to Wordnet Synsets.

* [Image-Net](http://image-net.org/)

ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images.

* [COCO](http://cocodataset.org/#download)

Common objects in context (COCO) is a large-scale object detection, segmentation, and captioning dataset.

Featuring:
Object segmentation,
Recognition in context,
Superpixel stuff segmentation,
330K images (>200K labeled),
1.5 million object instances,
80 object categories,
91 stuff categories,
5 captions per image,
250,000 people with keypoints.

* [LabelMe](http://labelme.csail.mit.edu/Release3.0/index.php?message=1)

The goal of LabelMe is to provide an online annotation tool to build image databases for computer vision research. You can contribute to the database by visiting the annotation tool.

* [Columbia University Image Library](https://www.cs.columbia.edu/CAVE/software/softlib/coil-100.php)

The Columbia University Image Library dataset features 100 different objects ranging from toys, personal care items, tablets and so on, imaged at every angle in a 360° rotation.

* [Open Images Dataset](https://storage.googleapis.com/openimages/web/download.html)

These annotation files cover the 600 boxable object classes, and span the 1,743,042 training images where we annotated bounding boxes, object segmentations, visual relationships, and localized narratives; as well as the full validation (41,620 images) and test (125,436 images) sets.

* [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/)

The Stanford Dogs dataset contains images of 120 breeds of dogs from around the world. This dataset has been built using images and annotation from ImageNet for the task of fine-grained image categorization. 

Contents of this dataset:
Number of categories: 120  
Number of images: 20,580 
Annotations: Class labels, Bounding boxes

* [Indoor Scene Recognition](http://web.mit.edu/torralba/www/indoor.html)

Indoor scene recognition is a challenging open problem in high level vision. Most scene recognition models that work well for outdoor scenes perform poorly in the indoor domain. The main difficulty is that while some indoor scenes (e.g. corridors) can be well characterized by global spatial properties, others (e.g., bookstores) are better characterized by the objects they contain. More generally, to address the indoor scenes recognition problem we need a model that can exploit local and global discriminative information.
The database contains 67 Indoor categories, and a total of 15620 images. The number of images varies across categories, but there are at least 100 images per category. All images are in jpg format. The images provided here are for research purposes only.


* [xView](http://xviewdataset.org/#dataset)

xView is one of the largest publicly available datasets of overhead imagery. It contains images from complex scenes around the world, annotated using bounding boxes.

* [VisualData](https://www.visualdata.io/discovery)

Best place to find and share computer vision datasets.

* [Google’s Open Images](https://ai.googleblog.com/2016/09/introducing-open-images-dataset.html)

A collection of 9 million URLs to images “that have been annotated with labels spanning over 6,000 categories” under Creative Commons.

* [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)

 A database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set.
 
* [CIFAR-10 dataset ](http://www.cs.toronto.edu/~kriz/cifar.html)
The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.
The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.

* [THE MNIST DATABASE](http://yann.lecun.com/exdb/mnist/)
The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.

* [Olivetti](https://cs.nyu.edu/~roweis/data.html)
Here are some datasets in MATLAB format.

* [The Yale Face Database](http://vision.ucsd.edu/content/yale-face-database)
The Yale Face Database (size 6.4MB) contains 165 grayscale images in GIF format of 15 individuals. There are 11 images per subject, one per different facial expression or configuration: center-light, w/glasses, happy, left-light, w/no glasses, normal, right-light, sad, sleepy, surprised, and wink.

* [Places](http://places.csail.mit.edu/index.html)
Scene-centric database with 205 scene categories and 2.5 million images with a category label.

* [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)
CelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter. CelebA has large diversities, large quantities, and rich annotations, including  10,177 number of identities, 202,599 number of face images, and 5 landmark locations, 40 binary attributes annotations per image.

* [102 Category Flower Dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html)
The flowers chosen to be flower commonly occuring in the United Kingdom. Each class consists of between 40 and 258 images. The details of the categories and the number of images for each class can be found on this category statistics page.
The images have large scale, pose and light variations. In addition, there are categories that have large variations within the category and several very similar categories. The dataset is visualized using isomap with shape and colour features.

* [Home Objects dataset](http://www.vision.caltech.edu/pmoreels/Datasets/Home_Objects_06/l)
This dataset contains random objects from home. The objects are taken mostly from kitchen, bathroom and living-room environments.
The directories containing the dataset are:
Training images and Test images.
Each directory contains a subdirectory named 'Gtruth/', containing ground truth .mat files. The .mat files contain a variable 'outline'. For training images, 'outline' contains the corners of a bounding box defining the model in the training image. For test images, 'outline' contains the names of the models present in the image along with a bounding box for each of them. If a same training object is defined by several training images, 'outline' references all these training images, with the same bounding box.


* [The Comprehensive Cars (CompCars) dataset](http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html)
The Comprehensive Cars (CompCars) dataset contains data from two scenarios, including images from web-nature and surveillance-nature. The web-nature data contains 163 car makes with 1,716 car models. There are a total of 136,726 images capturing the entire cars and 27,618 images capturing the car parts. The full car images are labeled with bounding boxes and viewpoints. Each car model is labeled with five attributes, including maximum speed, displacement, number of doors, number of seats, and type of car. The surveillance-nature data contains 50,000 car images captured in the front view.


 # Some of the common datasets finder:
 
 * [Google Dataset Search](https://datasetsearch.research.google.com/)

Google Dataset Search lets you find datasets wherever they’re hosted, whether it’s a publisher’s site, a digital library, or an author’s web page. It’s a phenomenal dataset finder, and it contains over 25 million datasets.
 
 * [Kaggle](https://www.kaggle.com/)
 
Inside Kaggle you’ll find all the code & data you need to do your data science work. Use over 19,000 public datasets and 200,000 public notebooks to conquer any analysis in no time.

 
